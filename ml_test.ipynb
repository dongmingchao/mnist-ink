{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIXEL_DEPTH = 255\n",
    "# IMAGE_SIZE = 20 # for chars74k\n",
    "IMAGE_SIZE = 28 # for MNIST\n",
    "NUM_CHANNELS = 1\n",
    "DATASETDIR = 'chars74k-lite'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileListFunc(filePathList):\n",
    "    fileList = []\n",
    "    for filePath in filePathList:\n",
    "        for top, dirs, nondirs in os.walk(filePath):\n",
    "            print(top, dirs, nondirs)\n",
    "            for item in nondirs:\n",
    "                fileList.append(os.path.join(top, item))\n",
    "    return fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(filename):\n",
    "    image_raw_data = tf.gfile.FastGFile(filename, 'rb').read()\n",
    "    img_data = tf.image.decode_jpeg(image_raw_data)\n",
    "    data = img_data.eval()\n",
    "    data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "character_mapping = {\n",
    "    0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9,\n",
    "    10: 'A', 11: 'B', 12: 'C', 13: 'D', 14: 'E', 15: 'F', 16: 'G',\n",
    "    17: 'H', 18: 'I', 19: 'J', 20: 'K', 21: 'L', 22: 'M', 23: 'N',\n",
    "    24: 'O', 25: 'P', 26: 'Q', 27: 'R', 28: 'S', 29: 'T', 30: 'U',\n",
    "    31: 'V', 32: 'W', 33: 'X', 34: 'Y', 35: 'Z', 36: 'a', 37: 'b',\n",
    "    38: 'c', 39: 'd', 40: 'e', 41: 'f', 42: 'g', 43: 'h', 44: 'i',\n",
    "    45: 'j', 46: 'k', 47: 'l', 48: 'm', 49: 'n', 50: 'o', 51: 'p',\n",
    "    52: 'q', 53: 'r', 54: 's', 55: 't', 56: 'u', 57: 'v', 58: 'w',\n",
    "    59: 'x', 60: 'y', 61: 'z'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n"
     ]
    }
   ],
   "source": [
    "print(ord('a')-61)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 来自于MNIST的原始数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting input/train-images-idx3-ubyte.gz\n",
      "Extracting input/train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy\n",
    "def extract_data(filename, num_images):\n",
    "    NUM_CHANNELS = 1\n",
    "    PIXEL_DEPTH = 255\n",
    "    \"\"\"Extract the images into a 4D tensor [image index, y, x, channels].\n",
    "    Values are rescaled from [0, 255] down to [-0.5, 0.5].\n",
    "    \"\"\"\n",
    "    print(\"Extracting\", filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(16)\n",
    "        buf = bytestream.read(IMAGE_SIZE * IMAGE_SIZE * num_images * NUM_CHANNELS)\n",
    "        data = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.float32)\n",
    "        data = (data - (PIXEL_DEPTH / 2.0)) / PIXEL_DEPTH\n",
    "        data = data.reshape(num_images, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    "        return data\n",
    "def extract_labels(filename, num_images):\n",
    "    \"\"\"Extract the labels into a vector of int64 label IDs.\"\"\"\n",
    "    print(\"Extracting\", filename)\n",
    "    with gzip.open(filename) as bytestream:\n",
    "        bytestream.read(8)\n",
    "        buf = bytestream.read(1 * num_images)\n",
    "        labels = numpy.frombuffer(buf, dtype=numpy.uint8).astype(numpy.int64)\n",
    "    return labels\n",
    "train_data = extract_data(\"input/train-images-idx3-ubyte.gz\", 60000)\n",
    "train_labels = extract_labels(\"input/train-labels-idx1-ubyte.gz\", 60000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 来自于chars74k的字母图片数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z,"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_labels = []\n",
    "for each in os.listdir(DATASETDIR):\n",
    "    dirname = DATASETDIR+'/'+each\n",
    "    if os.path.isdir(dirname):\n",
    "        print(each,end=',')\n",
    "        for filename in os.listdir(dirname):\n",
    "            train_data.append(extract_data(dirname+'/'+filename))\n",
    "            train_labels.append(ord(each)-61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data), len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_node = tf.placeholder(\n",
    "    tf.float32,\n",
    "    shape=(None, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS),\n",
    "    name=\"image_input\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_node = tf.placeholder(tf.int64, shape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = np.array(train_labels).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data = tf.placeholder(\n",
    "    tf.float32, shape=(None, IMAGE_SIZE, IMAGE_SIZE, NUM_CHANNELS)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_type():\n",
    "    return tf.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 66478\n",
    "# NUM_LABELS = 26 # for chars74k dataset\n",
    "NUM_LABELS = 10 # for mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(data, train=False):\n",
    "    # The variables below hold all the trainable weights. They are passed an\n",
    "    # initial value which will be assigned when we call:\n",
    "    # {tf.global_variables_initializer().run()}\n",
    "    conv1_weights = tf.Variable(\n",
    "        tf.truncated_normal(\n",
    "            [5, 5, NUM_CHANNELS, 32],  # 5x5 filter, depth 32.\n",
    "            stddev=0.1,\n",
    "            seed=SEED,\n",
    "            dtype=data_type(),\n",
    "        )\n",
    "    )\n",
    "    conv1_biases = tf.Variable(tf.zeros([32], dtype=data_type()))\n",
    "    conv2_weights = tf.Variable(\n",
    "        tf.truncated_normal([5, 5, 32, 64], stddev=0.1, seed=SEED, dtype=data_type())\n",
    "    )\n",
    "    conv2_biases = tf.Variable(tf.constant(0.1, shape=[64], dtype=data_type()))\n",
    "    fc1_weights = tf.Variable(  # fully connected, depth 512.\n",
    "        tf.truncated_normal(\n",
    "            [IMAGE_SIZE // 4 * IMAGE_SIZE // 4 * 64, 512],\n",
    "            stddev=0.1,\n",
    "            seed=SEED,\n",
    "            dtype=data_type(),\n",
    "        )\n",
    "    )\n",
    "    fc1_biases = tf.Variable(tf.constant(0.1, shape=[512], dtype=data_type()))\n",
    "    fc2_weights = tf.Variable(\n",
    "        tf.truncated_normal([512, NUM_LABELS], stddev=0.1, seed=SEED, dtype=data_type())\n",
    "    )\n",
    "    fc2_biases = tf.Variable(tf.constant(0.1, shape=[NUM_LABELS], dtype=data_type()))\n",
    "    layers = [fc1_weights, fc1_biases, fc2_weights, fc2_biases]\n",
    "    \"\"\"The Model definition.\"\"\"\n",
    "    # 2D convolution, with 'SAME' padding (i.e. the output feature map has\n",
    "    # the same size as the input). Note that {strides} is a 4D array whose\n",
    "    # shape matches the data layout: [image index, y, x, depth].\n",
    "    conv = tf.nn.conv2d(data, conv1_weights, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    # Bias and rectified linear non-linearity.\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv1_biases))\n",
    "    # Max pooling. The kernel size spec {ksize} also follows the layout of\n",
    "    # the data. Here we have a pooling window of 2, and a stride of 2.\n",
    "    pool = tf.nn.max_pool(\n",
    "        relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\"\n",
    "    )\n",
    "    conv = tf.nn.conv2d(pool, conv2_weights, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    relu = tf.nn.relu(tf.nn.bias_add(conv, conv2_biases))\n",
    "    pool = tf.nn.max_pool(\n",
    "        relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\"\n",
    "    )\n",
    "    # Reshape the feature map cuboid into a 2D matrix to feed it to the\n",
    "    # fully connected layers.\n",
    "    pool_shape = pool.get_shape().as_list()\n",
    "    reshape = tf.reshape(\n",
    "        pool, [tf.shape(pool)[0], pool_shape[1] * pool_shape[2] * pool_shape[3]]\n",
    "    )\n",
    "    # Fully connected layer. Note that the '+' operation automatically\n",
    "    # broadcasts the biases.\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, fc1_weights) + fc1_biases)\n",
    "    # Add a 50% dropout during training only. Dropout also scales\n",
    "    # activations such that no rescaling is needed at evaluation time.\n",
    "    if train:\n",
    "        hidden = tf.nn.dropout(hidden, 0.5, seed=SEED)\n",
    "    return tf.matmul(hidden, fc2_weights) + fc2_biases, layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits, layers = inference(train_data_node, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder:0' shape=(?,) dtype=int64>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        labels=train_labels_node, logits=logits\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_op = tf.argmax(logits, 1, name=\"predict_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "regularizers = 0\n",
    "for each in layers:\n",
    "    regularizers += tf.nn.l2_loss(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss += 5e-4 * regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer: set up a variable that's incremented once per batch and\n",
    "# controls the learning rate decay.\n",
    "batch = tf.Variable(0, dtype=data_type())\n",
    "# Decay once per epoch, using an exponential schedule starting at 0.01.\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    0.01,  # Base learning rate.\n",
    "    batch * BATCH_SIZE,  # Current index into the dataset.\n",
    "    train_size,  # Decay step.\n",
    "    0.95,  # Decay rate.\n",
    "    staircase=True,\n",
    ")\n",
    "# Use simple momentum for the optimization.\n",
    "optimizer = tf.train.MomentumOptimizer(learning_rate, 0.9).minimize(\n",
    "    loss, global_step=batch\n",
    ")\n",
    "\n",
    "# Predictions for the current training minibatch.\n",
    "train_prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Predictions for the test and validation, which we'll compute less often.\n",
    "eval_prediction = tf.nn.softmax(inference(eval_data)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_BATCH_SIZE = 64\n",
    "EVAL_FREQUENCY = 100  # Number of steps between evaluations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small utility function to evaluate a dataset by feeding batches of data to\n",
    "# {eval_data} and pulling the results from {eval_predictions}.\n",
    "# Saves memory and enables this to run on smaller GPUs.\n",
    "def eval_in_batches(data, sess):\n",
    "    \"\"\"Get all predictions for a dataset by running it in small batches.\"\"\"\n",
    "    size = data.shape[0]\n",
    "    if size < EVAL_BATCH_SIZE:\n",
    "        raise ValueError(\"batch size for evals larger than dataset: %d\" % size)\n",
    "    predictions = numpy.ndarray(shape=(size, NUM_LABELS), dtype=numpy.float32)\n",
    "    for begin in xrange(0, size, EVAL_BATCH_SIZE):\n",
    "        end = begin + EVAL_BATCH_SIZE\n",
    "        if end <= size:\n",
    "            predictions[begin:end, :] = sess.run(\n",
    "                eval_prediction, feed_dict={eval_data: data[begin:end, ...]}\n",
    "            )\n",
    "        else:\n",
    "            batch_predictions = sess.run(\n",
    "                eval_prediction, feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]}\n",
    "            )\n",
    "            predictions[begin:, :] = batch_predictions[begin - size :, :]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPORT_DIR = 'export'\n",
    "MODEL_DIR = 'output'\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "from six.moves import xrange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change original code\n",
    "# Create a saver for writing training checkpoints.\n",
    "saver = tf.train.Saver()\n",
    "# Create a builder for writing saved model for serving.\n",
    "if os.path.isdir(EXPORT_DIR):\n",
    "    shutil.rmtree(EXPORT_DIR)\n",
    "builder = tf.saved_model.builder.SavedModelBuilder(EXPORT_DIR)\n",
    "\n",
    "# Create a local session to run the training.\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下开始跑Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from output\\model.ckpt-8000\n",
      "INFO:tensorflow:Restoring parameters from output\\model.ckpt-8000\n",
      "Initialized!\n"
     ]
    }
   ],
   "source": [
    "# Run all the initializers to prepare the trainable parameters.\n",
    "tf.global_variables_initializer().run()\n",
    "### Change original code\n",
    "# Save checkpoint when training\n",
    "ckpt = tf.train.get_checkpoint_state(MODEL_DIR)\n",
    "if ckpt and ckpt.model_checkpoint_path:\n",
    "    print(\"Load from \" + ckpt.model_checkpoint_path)\n",
    "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "### Change original code\n",
    "# Create summary, logs will be saved, which can display in Tensorboard\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "merged = tf.summary.merge_all()\n",
    "writer = tf.summary.FileWriter(\n",
    "    os.path.join(MODEL_DIR, \"log\"), sess.graph\n",
    ")\n",
    "\n",
    "print(\"Initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 9375)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xrange(int(NUM_EPOCHS * train_size) // BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "step = 0\n",
    "offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "batch_data = train_data[offset : (offset + BATCH_SIZE), ...]\n",
    "batch_labels = train_labels[offset : (offset + BATCH_SIZE)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_labels.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = {train_data_node: batch_data, train_labels_node: batch_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.run(feed_dict=feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(predictions, labels):\n",
    "    \"\"\"Return the error rate based on dense predictions and sparse labels.\"\"\"\n",
    "    return 100.0 - (\n",
    "        100.0 * numpy.sum(numpy.argmax(predictions, 1) == labels) / predictions.shape[0]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SIZE = 5000\n",
    "validation_data = train_data[:VALIDATION_SIZE, ...]\n",
    "validation_labels = train_labels[:VALIDATION_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 (epoch 0.00), 176.2 ms\n",
      "Minibatch loss: 0.731, learning rate: 0.001748\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 100 (epoch 0.11), 6.2 ms\n",
      "Minibatch loss: 0.731, learning rate: 0.001748\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 200 (epoch 0.21), 5.2 ms\n",
      "Minibatch loss: 0.762, learning rate: 0.001748\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 300 (epoch 0.32), 5.0 ms\n",
      "Minibatch loss: 0.728, learning rate: 0.001748\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 400 (epoch 0.43), 5.0 ms\n",
      "Minibatch loss: 0.726, learning rate: 0.001748\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 500 (epoch 0.53), 5.2 ms\n",
      "Minibatch loss: 0.729, learning rate: 0.001748\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 600 (epoch 0.64), 5.1 ms\n",
      "Minibatch loss: 0.731, learning rate: 0.001748\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 700 (epoch 0.75), 5.1 ms\n",
      "Minibatch loss: 0.729, learning rate: 0.001748\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 800 (epoch 0.85), 5.1 ms\n",
      "Minibatch loss: 0.737, learning rate: 0.001748\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 900 (epoch 0.96), 5.1 ms\n",
      "Minibatch loss: 0.726, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1000 (epoch 1.07), 5.3 ms\n",
      "Minibatch loss: 0.732, learning rate: 0.001661\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 1100 (epoch 1.17), 5.7 ms\n",
      "Minibatch loss: 0.717, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1200 (epoch 1.28), 5.0 ms\n",
      "Minibatch loss: 0.720, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1300 (epoch 1.39), 5.1 ms\n",
      "Minibatch loss: 0.715, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1400 (epoch 1.49), 5.0 ms\n",
      "Minibatch loss: 0.725, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1500 (epoch 1.60), 5.0 ms\n",
      "Minibatch loss: 0.715, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1600 (epoch 1.71), 5.1 ms\n",
      "Minibatch loss: 0.715, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1700 (epoch 1.81), 5.0 ms\n",
      "Minibatch loss: 0.711, learning rate: 0.001661\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1800 (epoch 1.92), 5.0 ms\n",
      "Minibatch loss: 0.710, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 1900 (epoch 2.03), 5.0 ms\n",
      "Minibatch loss: 0.710, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2000 (epoch 2.13), 5.0 ms\n",
      "Minibatch loss: 0.709, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2100 (epoch 2.24), 5.7 ms\n",
      "Minibatch loss: 0.741, learning rate: 0.001578\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 2200 (epoch 2.35), 5.0 ms\n",
      "Minibatch loss: 0.717, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2300 (epoch 2.45), 4.8 ms\n",
      "Minibatch loss: 0.705, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2400 (epoch 2.56), 5.1 ms\n",
      "Minibatch loss: 0.704, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2500 (epoch 2.67), 5.0 ms\n",
      "Minibatch loss: 0.704, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2600 (epoch 2.77), 5.1 ms\n",
      "Minibatch loss: 0.702, learning rate: 0.001578\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2700 (epoch 2.88), 5.2 ms\n",
      "Minibatch loss: 0.713, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2800 (epoch 2.99), 5.0 ms\n",
      "Minibatch loss: 0.701, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 2900 (epoch 3.09), 5.1 ms\n",
      "Minibatch loss: 0.706, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 3000 (epoch 3.20), 5.1 ms\n",
      "Minibatch loss: 0.701, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 3100 (epoch 3.31), 5.6 ms\n",
      "Minibatch loss: 0.698, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 3200 (epoch 3.41), 4.9 ms\n",
      "Minibatch loss: 0.706, learning rate: 0.001499\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 3300 (epoch 3.52), 5.1 ms\n",
      "Minibatch loss: 0.693, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 3400 (epoch 3.63), 5.1 ms\n",
      "Minibatch loss: 0.779, learning rate: 0.001499\n",
      "Minibatch error: 4.7%\n",
      "Validation error: 91.3%\n",
      "Step 3500 (epoch 3.73), 5.1 ms\n",
      "Minibatch loss: 0.693, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 3600 (epoch 3.84), 5.0 ms\n",
      "Minibatch loss: 0.693, learning rate: 0.001499\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 3700 (epoch 3.95), 5.1 ms\n",
      "Minibatch loss: 0.704, learning rate: 0.001424\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 3800 (epoch 4.05), 5.0 ms\n",
      "Minibatch loss: 0.745, learning rate: 0.001424\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 91.3%\n",
      "Step 3900 (epoch 4.16), 5.1 ms\n",
      "Minibatch loss: 0.705, learning rate: 0.001424\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 4000 (epoch 4.27), 5.2 ms\n",
      "Minibatch loss: 0.688, learning rate: 0.001424\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 4100 (epoch 4.37), 5.9 ms\n",
      "Minibatch loss: 0.687, learning rate: 0.001424\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 4200 (epoch 4.48), 5.1 ms\n",
      "Minibatch loss: 0.685, learning rate: 0.001424\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 4300 (epoch 4.59), 5.1 ms\n",
      "Minibatch loss: 0.714, learning rate: 0.001424\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 4400 (epoch 4.69), 5.3 ms\n",
      "Minibatch loss: 0.706, learning rate: 0.001424\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 4500 (epoch 4.80), 5.2 ms\n",
      "Minibatch loss: 0.690, learning rate: 0.001424\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 4600 (epoch 4.91), 5.3 ms\n",
      "Minibatch loss: 0.682, learning rate: 0.001353\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 4700 (epoch 5.01), 5.1 ms\n",
      "Minibatch loss: 0.711, learning rate: 0.001353\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 4800 (epoch 5.12), 5.1 ms\n",
      "Minibatch loss: 0.684, learning rate: 0.001353\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 4900 (epoch 5.23), 5.1 ms\n",
      "Minibatch loss: 0.692, learning rate: 0.001353\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5000 (epoch 5.33), 5.1 ms\n",
      "Minibatch loss: 0.689, learning rate: 0.001353\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5100 (epoch 5.44), 6.0 ms\n",
      "Minibatch loss: 0.724, learning rate: 0.001353\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 91.3%\n",
      "Step 5200 (epoch 5.55), 5.1 ms\n",
      "Minibatch loss: 0.678, learning rate: 0.001353\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5300 (epoch 5.65), 5.0 ms\n",
      "Minibatch loss: 0.675, learning rate: 0.001353\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5400 (epoch 5.76), 5.1 ms\n",
      "Minibatch loss: 0.674, learning rate: 0.001353\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5500 (epoch 5.87), 5.2 ms\n",
      "Minibatch loss: 0.672, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5600 (epoch 5.97), 5.3 ms\n",
      "Minibatch loss: 0.671, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5700 (epoch 6.08), 5.2 ms\n",
      "Minibatch loss: 0.683, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5800 (epoch 6.19), 5.3 ms\n",
      "Minibatch loss: 0.672, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 5900 (epoch 6.29), 5.1 ms\n",
      "Minibatch loss: 0.684, learning rate: 0.001285\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 6000 (epoch 6.40), 5.1 ms\n",
      "Minibatch loss: 0.671, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 6100 (epoch 6.51), 5.9 ms\n",
      "Minibatch loss: 0.677, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 6200 (epoch 6.61), 5.0 ms\n",
      "Minibatch loss: 0.667, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 6300 (epoch 6.72), 5.2 ms\n",
      "Minibatch loss: 0.676, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 6400 (epoch 6.83), 5.1 ms\n",
      "Minibatch loss: 0.671, learning rate: 0.001285\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 6500 (epoch 6.93), 5.1 ms\n",
      "Minibatch loss: 0.680, learning rate: 0.001221\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 6600 (epoch 7.04), 5.0 ms\n",
      "Minibatch loss: 0.693, learning rate: 0.001221\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 6700 (epoch 7.15), 5.1 ms\n",
      "Minibatch loss: 0.663, learning rate: 0.001221\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 6800 (epoch 7.25), 5.0 ms\n",
      "Minibatch loss: 0.662, learning rate: 0.001221\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 6900 (epoch 7.36), 5.0 ms\n",
      "Minibatch loss: 0.663, learning rate: 0.001221\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7000 (epoch 7.47), 5.1 ms\n",
      "Minibatch loss: 0.660, learning rate: 0.001221\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7100 (epoch 7.57), 5.8 ms\n",
      "Minibatch loss: 0.664, learning rate: 0.001221\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7200 (epoch 7.68), 5.1 ms\n",
      "Minibatch loss: 0.665, learning rate: 0.001221\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7300 (epoch 7.79), 5.1 ms\n",
      "Minibatch loss: 0.660, learning rate: 0.001221\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7400 (epoch 7.89), 4.9 ms\n",
      "Minibatch loss: 0.659, learning rate: 0.001160\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7500 (epoch 8.00), 5.0 ms\n",
      "Minibatch loss: 0.718, learning rate: 0.001160\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 7600 (epoch 8.11), 4.9 ms\n",
      "Minibatch loss: 0.656, learning rate: 0.001160\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7700 (epoch 8.21), 5.0 ms\n",
      "Minibatch loss: 0.654, learning rate: 0.001160\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7800 (epoch 8.32), 4.9 ms\n",
      "Minibatch loss: 0.654, learning rate: 0.001160\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 7900 (epoch 8.43), 5.2 ms\n",
      "Minibatch loss: 0.660, learning rate: 0.001160\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 8000 (epoch 8.53), 5.0 ms\n",
      "Minibatch loss: 0.680, learning rate: 0.001160\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 8100 (epoch 8.64), 6.0 ms\n",
      "Minibatch loss: 0.708, learning rate: 0.001160\n",
      "Minibatch error: 3.1%\n",
      "Validation error: 91.3%\n",
      "Step 8200 (epoch 8.75), 5.1 ms\n",
      "Minibatch loss: 0.674, learning rate: 0.001160\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 8300 (epoch 8.85), 5.0 ms\n",
      "Minibatch loss: 0.652, learning rate: 0.001160\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 8400 (epoch 8.96), 5.0 ms\n",
      "Minibatch loss: 0.649, learning rate: 0.001102\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 8500 (epoch 9.07), 4.9 ms\n",
      "Minibatch loss: 0.654, learning rate: 0.001102\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 8600 (epoch 9.17), 5.1 ms\n",
      "Minibatch loss: 0.680, learning rate: 0.001102\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 8700 (epoch 9.28), 5.0 ms\n",
      "Minibatch loss: 0.650, learning rate: 0.001102\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 8800 (epoch 9.39), 4.9 ms\n",
      "Minibatch loss: 0.648, learning rate: 0.001102\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 8900 (epoch 9.49), 5.0 ms\n",
      "Minibatch loss: 0.663, learning rate: 0.001102\n",
      "Minibatch error: 1.6%\n",
      "Validation error: 91.3%\n",
      "Step 9000 (epoch 9.60), 5.1 ms\n",
      "Minibatch loss: 0.645, learning rate: 0.001102\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 9100 (epoch 9.71), 6.0 ms\n",
      "Minibatch loss: 0.645, learning rate: 0.001102\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 9200 (epoch 9.81), 5.0 ms\n",
      "Minibatch loss: 0.645, learning rate: 0.001102\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n",
      "Step 9300 (epoch 9.92), 5.0 ms\n",
      "Minibatch loss: 0.647, learning rate: 0.001047\n",
      "Minibatch error: 0.0%\n",
      "Validation error: 91.3%\n"
     ]
    }
   ],
   "source": [
    "# Loop through training steps.\n",
    "for step in xrange(int(NUM_EPOCHS * train_size) // BATCH_SIZE):\n",
    "    # Compute the offset of the current minibatch in the data.\n",
    "    # Note that we could use better randomization across epochs.\n",
    "    offset = (step * BATCH_SIZE) % (train_size - BATCH_SIZE)\n",
    "    batch_data = train_data[offset : (offset + BATCH_SIZE), ...]\n",
    "    batch_labels = train_labels[offset : (offset + BATCH_SIZE)]\n",
    "    # This dictionary maps the batch data (as a numpy array) to the\n",
    "    # node in the graph it should be fed to.\n",
    "    feed_dict = {train_data_node: batch_data, train_labels_node: batch_labels}\n",
    "    # Run the optimizer to update weights.\n",
    "    # sess.run(optimizer, feed_dict=feed_dict)\n",
    "    optimizer.run(feed_dict=feed_dict)\n",
    "    # print some extra information once reach the evaluation frequency\n",
    "    if step % EVAL_FREQUENCY == 0:\n",
    "        # fetch some extra nodes' data\n",
    "        ### Change original code\n",
    "        # Add summary\n",
    "        summary, l, lr, predictions = sess.run(\n",
    "            [merged, loss, learning_rate, train_prediction], feed_dict=feed_dict\n",
    "        )\n",
    "        writer.add_summary(summary, step)\n",
    "        elapsed_time = time.time() - start_time\n",
    "        start_time = time.time()\n",
    "        ### Change original code\n",
    "        # save model\n",
    "        if step % (EVAL_FREQUENCY * 10) == 0:\n",
    "            saver.save(\n",
    "                sess,\n",
    "                os.path.join(MODEL_DIR, \"model.ckpt\"),\n",
    "                global_step=step,\n",
    "            )\n",
    "        print(\n",
    "            \"Step %d (epoch %.2f), %.1f ms\"\n",
    "            % (\n",
    "                step,\n",
    "                float(step) * BATCH_SIZE / train_size,\n",
    "                1000 * elapsed_time / EVAL_FREQUENCY,\n",
    "            )\n",
    "        )\n",
    "        print(\"Minibatch loss: %.3f, learning rate: %.6f\" % (l, lr))\n",
    "        print(\"Minibatch error: %.1f%%\" % error_rate(predictions, batch_labels))\n",
    "        print(\n",
    "            \"Validation error: %.1f%%\"\n",
    "            % error_rate(\n",
    "                eval_in_batches(validation_data, sess), validation_labels\n",
    "            )\n",
    "        )\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change original code\n",
    "# Save model\n",
    "inputs = {tf.saved_model.signature_constants.PREDICT_INPUTS: train_data_node}\n",
    "outputs = {tf.saved_model.signature_constants.PREDICT_OUTPUTS: predict_op}\n",
    "serving_signatures = {\n",
    "    \"Infer\": tf.saved_model.signature_def_utils.predict_signature_def(  # tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY:\n",
    "        inputs, outputs\n",
    "    )\n",
    "}\n",
    "builder.add_meta_graph_and_variables(\n",
    "    sess,\n",
    "    [tf.saved_model.tag_constants.SERVING],\n",
    "    signature_def_map=serving_signatures,\n",
    "    assets_collection=tf.get_collection(tf.GraphKeys.ASSET_FILEPATHS),\n",
    "    clear_devices=True,\n",
    ")\n",
    "builder.save()\n",
    "\n",
    "# Finally print the result!\n",
    "test_error = error_rate(eval_in_batches(test_data, sess), test_labels)\n",
    "print(\"Test error: %.1f%%\" % test_error)\n",
    "if config.FLAGS.self_test:\n",
    "    print(\"test_error\", test_error)\n",
    "    assert test_error == 0.0, \"expected 0.0 test_error, got %.2f\" % (\n",
    "        test_error,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
